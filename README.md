# âœˆï¸ Twitter Sentiment Analysis Using LSTM ğŸŒŸ

## ğŸš€ Overview
- Analyze airline-related tweets ğŸ¦ to determine customer sentiments ğŸ˜Š ğŸ˜¡ ğŸ˜ using **LSTM (Long Short-Term Memory)** models. This project leverages the **Twitter US Airline Sentiment** dataset to classify tweets into **positive**, **negative**, and **neutral** sentiments.  
---

## ğŸ“„ Dataset  
ğŸ“‚ The dataset used is the [**Twitter US Airline Sentiment**](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment). It contains:  
- ğŸ“ **14,640 entries** representing customer reviews.  
- ğŸ§® **15 features**, including tweet metadata, sentiment labels, and reasons for sentiments.  

### ğŸ“Š Sentiment Distribution:  
- ğŸ˜Š **Positive**: 2,363  
- ğŸ˜ **Neutral**: 3,099  
- ğŸ˜¡ **Negative**: 9,178  
---

## ğŸ› ï¸ LSTM Architectures  

### ğŸ—ï¸ **Base LSTM Model:**  
1. **ğŸ“š Embedding Layer**: Maps vocabulary into 32-dimensional space.  
2. **âš™ï¸ Conv1D Layer**: Applies 32 filters with ReLU activation and MaxPooling1D.  
3. **ğŸ”„ Bidirectional LSTM Layer**: 64 units for capturing forward and backward dependencies.  
4. **ğŸš§ Dropout Layer**: Dropout rate of 0.5 to reduce overfitting.  
5. **ğŸ¯ Output Layer**: Dense layer with 3 units using the **softmax** activation function for classification.  

#### ğŸ§ª **Performance:**  
- ğŸŸ¢ **Initial Learning**: Rapid learning with increasing accuracy and decreasing loss.  
- ğŸ”´ **Overfitting**: Validation loss increases after a few epochs.
- ğŸ¯ **Accuracy**: 71%
---

### ğŸ—ï¸ **Improved LSTM Model:**  
1. **ğŸ“š Embedding Layer**: Similar to the base model.  
2. **ğŸ”„ First Bidirectional LSTM Layer**: 64 units to capture dependencies in both directions.  
3. **ğŸš§ Dropout Layer**: Prevents overfitting with a dropout rate of 0.5.  
4. **ğŸ”„ Second Bidirectional LSTM Layer**: Another 64-unit layer for deeper learning.  
5. **ğŸ¯ Output Layer**: Dense layer with 3 units and **sigmoid** activation for classification.  

#### ğŸ§ª **Performance:**  
- ğŸŸ¢ **Consistent Learning**: Gradual improvement in validation accuracy.  
- ğŸŸ¡ **Better Generalization**: Reduced overfitting compared to the base model.
- ğŸ¯ **Accuracy**: 76%
---

## ğŸ“Š Key Results  
- ğŸŸ¢ **Base Model**: Rapid learning but prone to overfitting.  
- ğŸŸ¡ **Improved Model**: Balanced training and validation with better performance.  
---

## ğŸ“ˆ Visualizations  

### ğŸ§© Sentiment Distribution ğŸ“Š  
A breakdown of positive, neutral, and negative sentiments in the dataset.  
![output](https://github.com/user-attachments/assets/aa60e4f5-abcb-461d-b69d-4fb64b654dae)

### ğŸ“Š Prediction Accuracy and Loss ğŸ“‰  
Plots showcasing model training and validation performance over epochs.  
![output](https://github.com/user-attachments/assets/130bd463-d761-4375-a46d-fa74be6eea67)


### ğŸ”¥ Confusion Matrix ğŸ”¢  
Illustrates how well the models classify the three sentiment categories.  
![output](https://github.com/user-attachments/assets/5551d605-26de-407b-ae50-8f16066ee94b)

---
